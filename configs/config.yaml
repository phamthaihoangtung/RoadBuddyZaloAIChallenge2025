# Example configuration for training
batch_size: 32
epochs: 10
learning_rate: 0.001
model_name: "placeholder"
infer_data_path: "data/public_test/public_test.json"
attn_implementation: "flash_attention_2"  # Options: "flash_attention_2" or "sdpa"
use_unsloth: false

# Quantization settings (new unified format)
quantization:
  enabled: false
  mode: "8bit"  # Options: "4bit" or "8bit"; Unsloth honors only "4bit"

# Wandb configuration for inference tracking
use_wandb: false  # Set to true to enable wandb logging
wandb_project: "road-buddy-inference"  # Wandb project name
wandb_run_name: null  # Optional: custom run name (auto-generated if null)
wandb_tags: []  # Optional: list of tags for the run

# For Unsloth, recommended model names:
# - "unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit"
# - "unsloth/Qwen2.5-VL-7B-Instruct"

# When use_unsloth is true, quantization controls load_in_4bit for Unsloth
# (Unsloth uses 4-bit by default when quantization is enabled)
